# FOP (ICASSP 2022)
Official implementation of FOP method as described in "Fusion and Orthogonal Projection for Improved Face-Voice Association"
![image](https://user-images.githubusercontent.com/57453957/155537286-5efb2f3c-878c-47d5-a4a5-cec5421a8219.png)

## Proposed Methodology
(Left) Overall method. Fundamentally, it is a two-stream pipeline which generates face and voice embeddings. We
propose fusion and orthogonal projection (FOP) mechanism (dotted red box). (Right) The architecture of multimodal fusion.
<p align="center"><img src="imgs/proposed_fop.jpg" width="50%"/>
<p align="center"><img src="imgs/gmf.jpg" width="50%"/>
## Requirements

## Comparison
![nway_new](https://user-images.githubusercontent.com/57453957/155538706-39c001ea-3b35-4868-bff5-57c60fc706cb.jpg)
![nway_sota_new](https://user-images.githubusercontent.com/57453957/155538714-304af301-d8b1-43c9-9367-2297af168cb2.jpg)

## Citing FOP
@article{sasnet,
  title={FUSION AND ORTHOGONAL PROJECTION FOR IMPROVED FACE-VOICE ASSOCIATION},
  author={Muhammad Saad Saeed and Muhammad Haris Khan and Shah Nawaz and Muhammad Haroon Yousaf and Alessio Del Bue},
  journal={Internation Conference on Acoustics, Speech, and Signal Processing (ICASSP-22)},
  year={2022}
}
